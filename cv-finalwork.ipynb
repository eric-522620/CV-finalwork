{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":16017,"databundleVersionId":708189,"sourceType":"competition"}],"dockerImageVersionId":29662,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://cdn3.vectorstock.com/i/1000x1000/98/02/set-of-monochrome-icons-with-kannada-numbers-vector-15469802.jpg)","metadata":{}},{"cell_type":"markdown","source":"### 导入库","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as  np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.callbacks import ReduceLROnPlateau","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2024-06-21T00:14:04.666886Z","iopub.execute_input":"2024-06-21T00:14:04.667280Z","iopub.status.idle":"2024-06-21T00:14:07.739750Z","shell.execute_reply.started":"2024-06-21T00:14:04.667211Z","shell.execute_reply":"2024-06-21T00:14:07.739026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 加载数据","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('../input/Kannada-MNIST/train.csv')\ntest=pd.read_csv('../input/Kannada-MNIST/test.csv')\nsample_sub=pd.read_csv('../input/Kannada-MNIST/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:14:07.742011Z","iopub.execute_input":"2024-06-21T00:14:07.742359Z","iopub.status.idle":"2024-06-21T00:14:13.744892Z","shell.execute_reply.started":"2024-06-21T00:14:07.742293Z","shell.execute_reply":"2024-06-21T00:14:13.744107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 初步了解数据","metadata":{}},{"cell_type":"code","source":"print('训练数据有 {} 行和 {} 列'.format(train.shape[0],train.shape[1]))\nprint('测试数据有 {} 行和 {} 列'.format(test.shape[0],test.shape[1]))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:14:13.746405Z","iopub.execute_input":"2024-06-21T00:14:13.746676Z","iopub.status.idle":"2024-06-21T00:14:13.751927Z","shell.execute_reply.started":"2024-06-21T00:14:13.746612Z","shell.execute_reply":"2024-06-21T00:14:13.751114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:14:13.753122Z","iopub.execute_input":"2024-06-21T00:14:13.753341Z","iopub.status.idle":"2024-06-21T00:14:13.790325Z","shell.execute_reply.started":"2024-06-21T00:14:13.753299Z","shell.execute_reply":"2024-06-21T00:14:13.789711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"现在可以看到给定的训练数据集中有785列。将在这里描述每一列的含义：\n\n- Label：这一列包含了我们要预测的标签，即目标值。这里的标签是从0到9的数字。我们稍后会绘制一个条形图，看看这些目标值的分布情况。\n- Pixel0到Pixel783：这些是图像矩阵的像素值。也就是说，每一行包含28 x 28 = 784个（在这里是0到783）值。每一个值表示图像矩阵中第i x 28 + j个像素位置的像素值\n","metadata":{}},{"cell_type":"code","source":"test.head(3)\ntest=test.drop('id',axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:14:13.793064Z","iopub.execute_input":"2024-06-21T00:14:13.793314Z","iopub.status.idle":"2024-06-21T00:14:13.804725Z","shell.execute_reply.started":"2024-06-21T00:14:13.793267Z","shell.execute_reply":"2024-06-21T00:14:13.804006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 确认类别分布\n","metadata":{}},{"cell_type":"code","source":"y=train.label.value_counts()\nsns.barplot(y.index,y)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:14:13.807852Z","iopub.execute_input":"2024-06-21T00:14:13.808305Z","iopub.status.idle":"2024-06-21T00:14:14.049469Z","shell.execute_reply.started":"2024-06-21T00:14:13.808129Z","shell.execute_reply":"2024-06-21T00:14:14.048735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"可以看到每个类别都被分到6000个示例","metadata":{}},{"cell_type":"markdown","source":"## 数据准备","metadata":{}},{"cell_type":"code","source":"X_train=train.drop('label',axis=1)\nY_train=train.label\n\nprint(X_train)\nprint(Y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:14:14.050651Z","iopub.execute_input":"2024-06-21T00:14:14.050890Z","iopub.status.idle":"2024-06-21T00:14:14.343060Z","shell.execute_reply.started":"2024-06-21T00:14:14.050845Z","shell.execute_reply":"2024-06-21T00:14:14.342238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 数据归一化\n\n对于大多数图像数据，像素值是0到255之间的整数。\n\n神经网络使用较小的权重值来处理输入，而具有大整数值的输入会干扰或减慢学习过程。因此，将像素值归一化，使每个像素值在0到1之间是一个良好的做法。\n\n将像素值范围设为0-1是合理的，并且图像仍然可以正常显示。\n\n这可以通过将所有像素值除以最大的像素值，即255来实现。这一操作适用于所有通道，无论图像中实际存在的像素值范围如何。","metadata":{}},{"cell_type":"code","source":"X_train=X_train/255\ntest=test/255","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:14:14.344316Z","iopub.execute_input":"2024-06-21T00:14:14.344586Z","iopub.status.idle":"2024-06-21T00:14:15.565349Z","shell.execute_reply.started":"2024-06-21T00:14:14.344536Z","shell.execute_reply":"2024-06-21T00:14:15.564659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 调整尺寸","metadata":{}},{"cell_type":"code","source":"print('训练数据的形状为',X_train.shape)\nprint('测试数据的形状为',test.shape)\n\n\nX_train=X_train.values.reshape(-1,28,28,1)\ntest=test.values.reshape(-1,28,28,1)\n\n\nprint('训练数据的形状为',X_train.shape)\nprint('测试数据的形状为',test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:14:15.567028Z","iopub.execute_input":"2024-06-21T00:14:15.567390Z","iopub.status.idle":"2024-06-21T00:14:15.575590Z","shell.execute_reply.started":"2024-06-21T00:14:15.567327Z","shell.execute_reply":"2024-06-21T00:14:15.574678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"一切就绪，我们将数据重塑为 60000 个高度 28、宽度 28 和 1 个通道的示例","metadata":{}},{"cell_type":"markdown","source":"### 对类别进行编码","metadata":{}},{"cell_type":"markdown","source":"对于标签数据，进行one-hot编码\n\n在神经网络中，one-hot编码有助于模型更好地理解和学习数据的类别特征。通过将每个类别分开表示，神经网络可以更有效地调整权重，以学习到类别间的关系。","metadata":{}},{"cell_type":"code","source":"print(Y_train)\nY_train=to_categorical(Y_train)\nprint(Y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:14:15.577670Z","iopub.execute_input":"2024-06-21T00:14:15.577966Z","iopub.status.idle":"2024-06-21T00:14:15.589114Z","shell.execute_reply.started":"2024-06-21T00:14:15.577903Z","shell.execute_reply":"2024-06-21T00:14:15.588030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 划分训练集和验证集","metadata":{}},{"cell_type":"markdown","source":"现在把训练数据拆分为训练集和验证集。15%的训练数据将用于验证目的。","metadata":{}},{"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(X_train,Y_train,random_state=42,test_size=0.15)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:14:15.590608Z","iopub.execute_input":"2024-06-21T00:14:15.590961Z","iopub.status.idle":"2024-06-21T00:14:16.542617Z","shell.execute_reply.started":"2024-06-21T00:14:15.590885Z","shell.execute_reply":"2024-06-21T00:14:16.542008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(X_train[0][:,:,0])","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:14:16.543944Z","iopub.execute_input":"2024-06-21T00:14:16.544269Z","iopub.status.idle":"2024-06-21T00:14:16.705288Z","shell.execute_reply.started":"2024-06-21T00:14:16.544212Z","shell.execute_reply":"2024-06-21T00:14:16.704586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 数据增强","metadata":{}},{"cell_type":"markdown","source":"为了避免过拟合问题，我们需要对手写数字数据集进行人工扩展。我们可以使现有的数据集变得更大。这个想法是通过小的变换来改变训练数据，以再现人们书写数字时可能发生的变化。\n\n例如，数字可能没有居中，比例不一致（有些人写大数字，有些人写小数字），图像可能旋转过...\n\n这些以保持标签不变的方式改变数组表示的训练数据的方法被称为数据增强技术。一些常用的数据增强方法包括灰度处理、水平翻转、垂直翻转、随机裁剪、颜色抖动、平移、旋转等。\n\n通过对我们的训练数据应用这些变换中的几种，我们可以轻松地将训练样本数量增加一倍或两倍，从而创建一个非常健壮的模型。","metadata":{}},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # 不将整个数据集的均值设置为0\n        samplewise_center=False,  # 不将每个样本的均值设置为0\n        featurewise_std_normalization=False,  # 不将整个数据集除以其标准差来归一化\n        samplewise_std_normalization=False,  # 不将每个样本除以其标准差来归一化\n        zca_whitening=False,  # 不应用ZCA白化\n        rotation_range=10,  # 随机旋转图像，旋转范围为0到10度\n        zoom_range=0.1,  # 随机缩放图像，缩放范围为10%\n        width_shift_range=0.1,  # 随机水平平移图像，平移范围为总宽度的10%\n        height_shift_range=0.1,  # 随机垂直平移图像，平移范围为总高度的10%\n        horizontal_flip=False,  # 不随机水平翻转图像\n        vertical_flip=False  # 不随机垂直翻转图像\n)\n\n\n\ndatagen.fit(X_train)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:14:16.706525Z","iopub.execute_input":"2024-06-21T00:14:16.706807Z","iopub.status.idle":"2024-06-21T00:14:16.821978Z","shell.execute_reply.started":"2024-06-21T00:14:16.706758Z","shell.execute_reply":"2024-06-21T00:14:16.821202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"对于数据增强，选择了以下操作：\n\n- 随机将一些训练图像旋转10度\n- 随机将一些训练图像缩放10%\n- 随机将图像在水平位置上平移宽度的10%\n- 随机将图像在垂直位置上平移高度的10%\n\n没有应用垂直翻转或水平翻转，因为这可能导致对对称数字（如6和9）的误分类。","metadata":{}},{"cell_type":"markdown","source":"## 构建模型","metadata":{}},{"cell_type":"code","source":"# model = Sequential([\n#     Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n#                  activation ='relu', input_shape = (28,28,1)),\n#     Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n#                  activation ='relu'),\n#     BatchNormalization(momentum=.15),\n#     MaxPool2D(pool_size=(2,2)),\n#     Dropout(0.25),\n#     Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n#                  activation ='relu'),\n#     Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n#                  activation ='relu'),\n#     BatchNormalization(momentum=0.15),\n#     MaxPool2D(pool_size=(2,2), strides=(2,2)),\n#     Dropout(0.25),\n#     Flatten(),\n#     Dense(256, activation = \"relu\"),\n#     Dropout(0.4),\n#     Dense(10, activation = \"softmax\")\n# ])\n\n\n# model=Sequential([\n#     Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),  # 输出尺寸：(26, 26, 32)，输入形状为 (28, 28, 1)\n#     Conv2D(64, (3, 3), activation='relu'),  # 输出尺寸：(24, 24, 64)\n#     MaxPool2D(pool_size=(2, 2)),  # 输出尺寸：(12, 12, 64)，池化层将每个特征图尺寸减半\n#     Dropout(0.25),  # 输出尺寸保持不变：(12, 12, 64)，Dropout只在训练时起作用\n#     Flatten(),  # 输出尺寸：(12 * 12 * 64) = (9216)，将多维特征图展平成一维向量\n#     Dense(256, activation='relu'),  # 输出尺寸：(256)，全连接层有256个神经元\n#     Dropout(0.25),  # 输出尺寸保持不变：(256)，Dropout只在训练时起作用\n#     Dense(10, activation='softmax')  # 输出尺寸：(10)，全连接层有10个神经元，对应于10个类别的输出\n# ])\n\n# alexnet\n# model = Sequential([\n#     # 第一个卷积层\n#     Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=(28, 28, 1), padding='same'),  # 使用padding='same'适应28x28输入\n#     MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same'),\n\n#     # 第二个卷积层\n#     Conv2D(256, (5, 5), activation='relu', padding='same'),\n#     MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same'),\n\n#     # 第三个卷积层\n#     Conv2D(384, (3, 3), activation='relu', padding='same'),\n\n#     # 第四个卷积层\n#     Conv2D(384, (3, 3), activation='relu', padding='same'),\n\n#     # 第五个卷积层\n#     Conv2D(256, (3, 3), activation='relu', padding='same'),\n#     MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same'),\n\n#     # Flatten层将多维特征图展平成一维向量\n#     Flatten(),\n\n#     # 全连接层\n#     Dense(4096, activation='relu'),\n#     Dropout(0.5),\n#     Dense(4096, activation='relu'),\n#     Dropout(0.5),\n\n#     # 输出层\n#     Dense(10, activation='softmax')\n# ])\n\n# lenet\nmodel = Sequential([\n    # 第一个卷积层\n    Conv2D(6, (5, 5), activation='relu', input_shape=(28, 28, 1), padding='same'),  # 输出尺寸：(28, 28, 6)\n    MaxPool2D(pool_size=(2, 2)),  # 输出尺寸：(14, 14, 6)\n\n    # 第二个卷积层\n    Conv2D(16, (5, 5), activation='relu'),  # 输出尺寸：(10, 10, 16)\n    MaxPool2D(pool_size=(2, 2)),  # 输出尺寸：(5, 5, 16)\n\n    # Flatten层将多维特征图展平成一维向量\n    Flatten(),  # 输出尺寸：(5 * 5 * 16) = (400)\n\n    # 全连接层\n    Dense(120, activation='relu'),  # 输出尺寸：(120)\n    Dense(84, activation='relu'),   # 输出尺寸：(84)\n\n    # 输出层\n    Dense(10, activation='softmax')  # 输出尺寸：(10)，10个类别\n])","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:14:16.823453Z","iopub.execute_input":"2024-06-21T00:14:16.823831Z","iopub.status.idle":"2024-06-21T00:14:17.058464Z","shell.execute_reply.started":"2024-06-21T00:14:16.823777Z","shell.execute_reply":"2024-06-21T00:14:17.057701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-06-21T00:14:17.059926Z","iopub.execute_input":"2024-06-21T00:14:17.060236Z","iopub.status.idle":"2024-06-21T00:14:17.067197Z","shell.execute_reply.started":"2024-06-21T00:14:17.060180Z","shell.execute_reply":"2024-06-21T00:14:17.066399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Unhide Above output to see the summary**","metadata":{}},{"cell_type":"markdown","source":"### 学习率衰减","metadata":{}},{"cell_type":"markdown","source":"为了使优化器更快地收敛并更接近损失函数的全局最小值，我使用了一种学习率（LR）的退火方法。\n\n学习率越高，步伐越大，收敛越快。然而，较高的学习率会导致采样非常粗糙，优化器可能会陷入局部最小值。\n\n在训练过程中，最好是逐渐减小学习率，以有效地达到损失函数的全局最小值。\n\n为了保持较高学习率带来的快速计算优势，我根据需要（当准确率没有提高时），在每X步（epoch）动态减少学习率。\n\n使用Keras.callbacks中的ReduceLROnPlateau函数，我选择在准确率连续3个epoch没有提高后，将学习率减半。","metadata":{}},{"cell_type":"code","source":"# 定义优化器\noptimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n# 使用Adam优化器，初始学习率为0.001，beta_1和beta_2是用于一阶和二阶矩估计的指数衰减率\n\n# 编译模型\nmodel.compile(optimizer=optimizer, loss=['categorical_crossentropy'], metrics=['accuracy'])\n# 编译模型，使用Adam优化器，多分类交叉熵作为损失函数，评估指标为准确率\n\n# 设置学习率退火器\n# ReduceLROnPlateau是Keras中的回调函数，用于在模型性能不提升时减少学习率\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',  # monitor='val_acc'：监控验证集上的准确率（val_acc）\n                                            patience=3,  # patience=3：如果验证集上的准确率在连续3个epoch没有提升，则触发学习率减少\n                                            verbose=1,  # verbose=1：设置为1时，会在减少学习率时输出通知消息\n                                            factor=0.5,  # factor=0.5：减少学习率的因子，每次减少到当前学习率的50%\n                                            min_lr=0.00001) # min_lr=0.00001：学习率的下限，不会减少到这个值以下","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:14:17.068349Z","iopub.execute_input":"2024-06-21T00:14:17.068572Z","iopub.status.idle":"2024-06-21T00:14:17.166092Z","shell.execute_reply.started":"2024-06-21T00:14:17.068535Z","shell.execute_reply":"2024-06-21T00:14:17.165483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 训练模型 <a id='5'></a>","metadata":{}},{"cell_type":"code","source":"epochs=30 \nbatch_size=64\n\n# 训练模型\nhistory = model.fit_generator(\n    datagen.flow(X_train, y_train, batch_size=batch_size),  # 使用datagen生成增强后的训练数据\n    epochs=epochs,  # 训练的总轮数\n    validation_data=(X_test, y_test),  # 验证数据集，用于评估模型性能\n    verbose=2,  # 显示训练过程的详细程度，2表示每个epoch输出一次日志信息\n    steps_per_epoch=X_train.shape[0] // batch_size,  # 每个epoch包含的步骤数，等于训练集样本数除以批量大小\n    callbacks=[learning_rate_reduction]  # 回调函数列表，这里包含学习率退火器\n)\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-06-21T00:14:17.167354Z","iopub.execute_input":"2024-06-21T00:14:17.167578Z","iopub.status.idle":"2024-06-21T00:15:05.286530Z","shell.execute_reply.started":"2024-06-21T00:14:17.167540Z","shell.execute_reply":"2024-06-21T00:15:05.285361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 评估模型 <a id='6'></a>","metadata":{}},{"cell_type":"code","source":"fig,ax=plt.subplots(2,1)\nfig.set\nx=range(1,1+epochs)\nax[0].plot(x,history.history['loss'],color='red')\nax[0].plot(x,history.history['val_loss'],color='blue')\n\nax[1].plot(x,history.history['accuracy'],color='red')\nax[1].plot(x,history.history['val_accuracy'],color='blue')\nax[0].legend(['trainng loss','validation loss'])\nax[1].legend(['trainng acc','validation acc'])\nplt.xlabel('Number of epochs')\nplt.ylabel('accuracy')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:15:05.287961Z","iopub.status.idle":"2024-06-21T00:15:05.288468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"绘制了模型性能的图表。可以看到，X轴表示训练的轮数（epochs），Y轴表示模型性能的变化。","metadata":{}},{"cell_type":"markdown","source":"### 绘制混淆矩阵\n\n","metadata":{}},{"cell_type":"code","source":"y_pre_test=model.predict(X_test)\ny_pre_test=np.argmax(y_pre_test,axis=1)\ny_test=np.argmax(y_test,axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:15:05.289730Z","iopub.status.idle":"2024-06-21T00:15:05.290224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf=confusion_matrix(y_test,y_pre_test)\nconf=pd.DataFrame(conf,index=range(0,10),columns=range(0,10))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:15:05.291486Z","iopub.status.idle":"2024-06-21T00:15:05.292128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:15:05.293463Z","iopub.status.idle":"2024-06-21T00:15:05.293992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(conf, annot=True,annot_kws={\"size\": 16},cmap=plt.cm.Blues)# font size","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:15:05.295250Z","iopub.status.idle":"2024-06-21T00:15:05.296034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"在这里，可以看到模型在几乎所有数字上表现得相当不错。但是似乎在以下几对数字之间存在一些混淆：\n\n- 0 和 1：我们可以观察到一些0和1被错误分类。\n- 7 和 6：我们可以观察到一些6和7被错误分类。","metadata":{}},{"cell_type":"markdown","source":"## 进一步调查\n\n继续查看一些被错误分类的图像，并将简单地检查它们，以了解它们是否是难以预测的情况。","metadata":{}},{"cell_type":"code","source":"x=(y_pre_test-y_test!=0).tolist()\nx=[i for i,l in enumerate(x) if l!=False]","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:15:05.297151Z","iopub.status.idle":"2024-06-21T00:15:05.297700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax=plt.subplots(1,4,sharey=False,figsize=(15,15))\n\nfor i in range(4):\n    ax[i].imshow(X_test[x[i]][:,:,0])\n    ax[i].set_xlabel('Real {}, Predicted {}'.format(y_test[x[i]],y_pre_test[x[i]]))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:15:05.298970Z","iopub.status.idle":"2024-06-21T00:15:05.299454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 提交数据\n","metadata":{}},{"cell_type":"code","source":"test=pd.read_csv('../input/Kannada-MNIST/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:15:05.301158Z","iopub.status.idle":"2024-06-21T00:15:05.301753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_id=test.id\n\ntest=test.drop('id',axis=1)\ntest=test/255\ntest=test.values.reshape(-1,28,28,1)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:15:05.303108Z","iopub.status.idle":"2024-06-21T00:15:05.303799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:15:05.305135Z","iopub.status.idle":"2024-06-21T00:15:05.305643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pre=model.predict(test)     # 预测结果\ny_pre=np.argmax(y_pre,axis=1) # 改变预测为标签","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:15:05.306789Z","iopub.status.idle":"2024-06-21T00:15:05.307263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub['label']=y_pre\nsample_sub.to_csv('submission.csv',index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:15:05.308404Z","iopub.status.idle":"2024-06-21T00:15:05.309087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T00:15:05.310033Z","iopub.status.idle":"2024-06-21T00:15:05.310700Z"},"trusted":true},"execution_count":null,"outputs":[]}]}